{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import *\n",
    "from src.model import *\n",
    "from src.train_test import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "from src.vis import *\n",
    "from src.gradient import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_data_loader = data_loader(dataset_name = 'CIFAR10', \n",
    "                                batch_size = batch_size, \n",
    "                                train=True)\n",
    "test_data_loader = data_loader(dataset_name = 'CIFAR10', \n",
    "                                batch_size = batch_size, \n",
    "                                train=False)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'CIFAR17_add000'\n",
    "\n",
    "# initialize model\n",
    "model = KNOWN_MODELS[model_name]\n",
    "model = model.to(device)\n",
    "\n",
    "plot_training_acc(model, train_data_loader,\n",
    "                  model_name=model_name, data_name='CIFAR10', total_trails=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pos_grad_dict and neg_grad_dict for anchor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/26775 [00:00<02:54, 153.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of postive samples:  26775\n",
      "Number of negative samples:  4902\n",
      "Use trail 1 to compute conflicting gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26775/26775 [03:08<00:00, 142.33it/s]\n",
      "  0%|          | 16/4902 [00:00<00:32, 150.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data 26775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4902/4902 [00:32<00:00, 149.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data 4902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CIFAR17_add210'\n",
    "# initialize model\n",
    "model = KNOWN_MODELS[model_name]\n",
    "model = model.to(device)\n",
    "\n",
    "pos_grad_dict, neg_grad_dict = get_graddict(model=model, \n",
    "                                            model_name=model_name, data_name='CIFAR10',\n",
    "                                            train_data_loader=train_data_loader, num_trail=5, \n",
    "                                            pos_thre=5, neg_thre=0,\n",
    "#                                             compute_index=True, \n",
    "                                            compute_index=False, \n",
    "                                            vis=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pos_grad_dict and neg_grad_dict for neighbor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/26775 [00:00<01:21, 328.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of postive samples:  26775\n",
      "Number of negative samples:  4902\n",
      "Use trail 1 to compute conflicting gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 12508/26775 [00:37<01:35, 149.20it/s]"
     ]
    }
   ],
   "source": [
    "model_name = 'CIFAR17_add210'\n",
    "neighbor_name = 'CIFAR17_add220'\n",
    "# initialize model\n",
    "neighbor_model = KNOWN_MODELS[neighbor_name]\n",
    "neighbor_model = neighbor_model.to(device)\n",
    "\n",
    "pos_grad_dict, neg_grad_dict = get_neighbor_graddict(model_name=model_name,\n",
    "                          neighbor_model=neighbor_model,\n",
    "                          neighbor_model_name=neighbor_name,\n",
    "                          data_name='CIFAR10',\n",
    "                          train_data_loader=train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights contradiction visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# weight_contradict(pos_grad_dict, neg_grad_dict, method='sign')\n",
    "# weight_contradict(pos_grad_dict, neg_grad_dict, method='level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get layer contradiction level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg of weight contradiction level for each layer\n",
    "for name, grad_pos in pos_grad_dict.items():\n",
    "    if 'weight' in name:\n",
    "        grad_neg = neg_grad_dict[name]\n",
    "\n",
    "        conflict_level = (torch.sign(grad_pos) != torch.sign(grad_neg)) * (torch.abs(grad_pos - grad_neg))\n",
    "        \n",
    "        conflict_level = conflict_level.mean(dim=tuple(range(1, len(conflict_level.shape)))) # sum over kernel size\n",
    "        \n",
    "        layer_conflict_level = conflict_level.mean().item()\n",
    "        print(name, layer_conflict_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body.cnn1.conv.weight 0.6552368998527527\n",
      "body.cnn2.conv.weight 0.15954236686229706\n",
      "body.cnn3.conv.weight 0.18937832117080688\n",
      "head.dense.fc1.weight 0.08281862735748291\n",
      "head.dense.fc2.weight 0.04943676292896271\n"
     ]
    }
   ],
   "source": [
    "# max of weight contradiction level for each layer\n",
    "for name, grad_pos in pos_grad_dict.items():\n",
    "    if 'weight' in name:\n",
    "        grad_neg = neg_grad_dict[name]\n",
    "\n",
    "        conflict_level = (torch.sign(grad_pos) != torch.sign(grad_neg)) * (torch.abs(grad_pos - grad_neg))\n",
    "        \n",
    "        conflict_level = conflict_level.mean(dim=tuple(range(1, len(conflict_level.shape)))) # sum over kernel size\n",
    "        \n",
    "        layer_conflict_level = conflict_level.max().item()\n",
    "        print(name, layer_conflict_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body.cnn1.conv.weight 0.043868374079465866\n",
      "body.cnn2.conv.weight 0.0041794911958277225\n",
      "body.cnn3.conv.weight 0.0036977888084948063\n",
      "head.dense.fc1.weight 0.000469876074930653\n",
      "head.dense.fc2.weight 0.000319293380016461\n"
     ]
    }
   ],
   "source": [
    "# variance of weight contradiction level for each layer\n",
    "for name, grad_pos in pos_grad_dict.items():\n",
    "    if 'weight' in name:\n",
    "        grad_neg = neg_grad_dict[name]\n",
    "\n",
    "        conflict_level = (torch.sign(grad_pos) != torch.sign(grad_neg)) * (torch.abs(grad_pos - grad_neg))\n",
    "        \n",
    "        conflict_level = conflict_level.mean(dim=tuple(range(1, len(conflict_level.shape)))) # sum over kernel size\n",
    "        \n",
    "        layer_conflict_level = conflict_level.var().item()\n",
    "        print(name, layer_conflict_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir('checkpoints/'):\n",
    "    if folder.startswith('CIFAR17-CIFAR10-model'):\n",
    "        os.rename(os.path.join('checkpoints/', folder),\n",
    "                 os.path.join('checkpoints/', \n",
    "                              'CIFAR17_add000-CIFAR10-model'+folder.split('CIFAR17-CIFAR10-model')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_trace = ['CIFAR17_add000', 'CIFAR17_add010', 'CIFAR17_add110', 'CIFAR17_add210']\n",
    "\n",
    "logfile = open('log/train_trace.log').readlines()\n",
    "for j in logfile:\n",
    "    if 'INFO:trace:Update model name' in j:\n",
    "        initial_trace.append(j.strip().split(' ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIFAR17_add000',\n",
       " 'CIFAR17_add010',\n",
       " 'CIFAR17_add110',\n",
       " 'CIFAR17_add210',\n",
       " 'CIFAR17_add211',\n",
       " 'CIFAR17_add212',\n",
       " 'CIFAR17_add222',\n",
       " 'CIFAR17_add232',\n",
       " 'CIFAR17_add332',\n",
       " 'CIFAR17_add333',\n",
       " 'CIFAR17_add334',\n",
       " 'CIFAR17_add434']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increase 2th layer\n",
      "Increase 1th layer\n",
      "Increase 1th layer\n",
      "Increase 3th layer\n",
      "Increase 3th layer\n",
      "Increase 2th layer\n",
      "Increase 2th layer\n",
      "Increase 1th layer\n",
      "Increase 3th layer\n",
      "Increase 3th layer\n",
      "Increase 1th layer\n"
     ]
    }
   ],
   "source": [
    "for trace in initial_trace:\n",
    "    i,j,k = int(trace.split('add')[1][0]), \\\n",
    "            int(trace.split('add')[1][1]), \\\n",
    "            int(trace.split('add')[1][2]) # current index of model\n",
    "    \n",
    "    if 'lasti' in locals():\n",
    "        incre_i, incre_j, incre_k = i-lasti, j-lastj, k-lastk\n",
    "        ct = 1\n",
    "        for layer in [incre_i, incre_j, incre_k]:\n",
    "            if layer == 1:\n",
    "                print('Increase {}th layer'.format(ct))\n",
    "                break\n",
    "            ct += 1\n",
    "    \n",
    "    lasti, lastj, lastk = i,j,k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207.2010955810547px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 121.73912572860718,
   "position": {
    "height": "143.4646759033203px",
    "left": "882.1739501953125px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
